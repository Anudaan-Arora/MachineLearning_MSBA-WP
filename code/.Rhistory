tab_store
round(tab_obs/sum(tab_obs)*100,1)
tab_store
round(tab_obs/sum(tab_obs)*100,1)
i_admit
length(i_admit)
ls
dim(nw_check)
dim(new_data)
607/11201
607/10692
0.05419*10692
numsim = 1000
tab_store = array(NA,c(9,5))
colnames(tab_store) = names(tab_obs)
tab_sim = c()
admitsize = 580
#loop over deciles
for(ii in 2:10){
tab_sim = c()
# identify indices of applicants
ii_merit = which(nw_check$quantile_bin>=ii & nw_check$quantile_bin<=10)
for(n in 1:numsim){
tab_sim = rbind(tab_sim,table(sample(x=nw_check$race[ii_merit],replace=FALSE,size=admitsize))/admitsize)
}
tab_store[ii-1,] = round(colMeans(tab_sim)*100,1)
}
tab_store
# we will be sampling conditional on merit as defined by academic decile location
numsim = 1000
tab_store = array(NA,c(9,5))
colnames(tab_store) = names(tab_obs)
tab_sim = c()
admitsize = 607
#loop over deciles
for(ii in 2:10){
tab_sim = c()
# identify indices of applicants
ii_merit = which(nw_check$quantile_bin>=ii & nw_check$quantile_bin<=10)
for(n in 1:numsim){
tab_sim = rbind(tab_sim,table(sample(x=nw_check$race[ii_merit],replace=FALSE,size=admitsize))/admitsize)
}
tab_store[ii-1,] = round(colMeans(tab_sim)*100,1)
}
tab_store
xtable(tabstore)
xtable(tab_store)
rownames(tabstore)
rownames(tab_store)
rownames(tab_store) = c("\\90%","\\80%")
"\\90%"
rownames(tab_store) = c("\\90%","\\80%","\\70%","\\60%","\\50%","\\40%","\\30%","\\20%","\\10%")
tab_store
xtable(tab_store)
rownames(tab_store) = c("90%","80%","70%","60%","50%","40%","30%","20%","10%")
xtable(tab_store)
numsim = 5000
tab_store = array(NA,c(9,5))
colnames(tab_store) = names(tab_obs)
tab_sim = c()
admitsize = 607
#loop over deciles
for(ii in 2:10){
tab_sim = c()
# identify indices of applicants
ii_merit = which(nw_check$quantile_bin>=ii & nw_check$quantile_bin<=10)
for(n in 1:numsim){
tab_sim = rbind(tab_sim,table(sample(x=nw_check$race[ii_merit],replace=FALSE,size=admitsize))/admitsize)
}
tab_store[ii-1,] = round(colMeans(tab_sim)*100,1)
}
tab_store
round(tab_obs/sum(tab_obs)*100,1)
rownames(tab_store) = c("90%","80%","70%","60%","50%","40%","30%","20%","10%")
xtable(tab_store)
xtable(round(tab_obs/sum(tab_obs)*100,1))
xtable(round(t(tab_obs)/sum(tab_obs)*100,1))
# change base categories and making decision binary variable
data_recombine_clean <- within(data_recombine_clean, gender <- relevel(gender, ref = "Male"))
data_recombine_clean <- within(data_recombine_clean, race <- relevel(race, ref = "Asian"))
data_recombine_clean$decision = (data_recombine_clean$decision=="Admit")
data_recombine_clean$decision = (data_recombine_clean$decision=="Admit")
logitfit = glm(decision~gender+race+MCAT+GPA+GPA_sci+casper+gender*race,data = data_recombine_clean,family = 'binomial')
logitfit = glm(decision~.,data = data_recombine_clean,family = 'binomial')
logitfit = glm(decision~gender+race+MCAT+GPA+GPA_sci+casper,data = data_recombine_clean,family = 'binomial')
data_recombine_clean
# Texas Tech summary
library(vioplot)
library(ggplot2)
library(gapminder)
library(glmnet)
library(xtable)
library(Hmisc)
source("functions.R")
###############################
#  Code Unique to the School  #
###############################
data21 = read.csv("../TTUHSC_2021.csv"); data21$year = 2021
data22 = read.csv("../TTUHSC_2022.csv"); data22$year = 2022
data_all = rbind(data21,data22)
# remove international
i_international = which(data_all$Ethnicity=="International")
data_all = data_all[-i_international,]
# subset to students offered admission
admit_logic =  (data_all$Status_Description=="Matriculated" | data_all$Status_Description=="Withdrawn After Acceptance" | data_all$Status_Description=="Offer Declined" | data_all$Status_Description=="Deferred" | data_all$Status_Description=="Admitted")
# what are the admit ids
ids = which(admit_logic)
# subset data to admits, call it "data"
data = subset(data_all,subset = admit_logic)
# also subset to rejects
data_reject = data_all[-ids,]
# add reject/admit variable
data_reject$decision = "Reject"
data$decision = "Admit"
# data recombine
data_recombine = rbind(data,data_reject)
schoolname = "Texas Tech"
###########################
# data recombine analysis
###########################
# focus on outcomes: (1) MCAT (2) GPA & (3) Science GPA
MCAT = as.numeric(data_recombine$MCAT)
GPA = as.numeric(data_recombine$GPA_Overall)
GPA_sci = as.numeric(data_recombine$GPA_Science)
casper = as.numeric(data_recombine$CASPer)
year = data_recombine$year
status = data_recombine$Status_Description
# extract gender and race variables
gender = data_recombine$Gender
race = data_recombine$Ethnicity
race[race=="Black or African American "] <- "African American"
race[race=="American Indian or Alaska Native Other Hispanic, Latino, or of Spanish origin; Hispanic, Latino, or of Spanish origin; Mexican/Chicano"] <- "American Indian"
race[race=="Black or African American; Other "] <- "African American"
race[race=="Other "] <- "Unreported"
race[race==" "] <- "Unreported"
race[race=="White "] <- "White/Caucasian"
race[race=="White/Caucasian"] <- "White"
race[race=="American Indian or Alaska Native; White Hispanic, Latino, or of Spanish origin; Mexican/Chicano"] <- "American Indian"
race[race==" Hispanic, Latino, or of Spanish origin; Mexican/Chicano"] <- "Hispanic"
race[race==" Puerto Rican; Hispanic, Latino, or of Spanish origin"] <- "Hispanic"
race[race==" Brazillian; Hispanic, Latino, or of Spanish origin"] <- "Hispanic"
race[race==" Dominican; Hispanic, Latino, or of Spanish origin"] <- "Hispanic"
race[race==" Brazil; Hispanic, Latino, or of Spanish origin"] <- "Hispanic"
race[race=="Asian "] <- "Asian"
race[race=="Multiple"] <- "Other"
race[race=="Unreported"] <- "Other"
race = as.factor(race)
gender = as.factor(gender)
decision = as.factor(data_recombine$decision)
# performing similar split to SFFA expert report
race_AA = (race=="African American")
race_AA[which(race_AA==TRUE)] = "African American"
race_AA[which(race_AA=="FALSE")] = "Non-African American"
race_White = (race=="White")
race_White[which(race_White==TRUE)] = "White"
race_White[which(race_White=="FALSE")] = "Non-White"
race_Asian = (race=="Asian")
race_Asian[which(race_Asian==TRUE)] = "Asian"
race_Asian[which(race_Asian=="FALSE")] = "Non-Asian"
# clean data frame with all we need to plot
data_recombine_clean = data.frame(gender,race,MCAT,GPA,GPA_sci,decision,casper,year,race_AA,race_White,race_Asian,status)
sum(data_recombine_clean$decision=="Admit") #check
# change base categories and making decision binary variable
data_recombine_clean <- within(data_recombine_clean, gender <- relevel(gender, ref = "Male"))
data_recombine_clean <- within(data_recombine_clean, race <- relevel(race, ref = "Asian"))
data_recombine_clean$decision = (data_recombine_clean$decision=="Admit")
logitfit = glm(decision~gender+race+MCAT+GPA+GPA_sci+casper,data = data_recombine_clean,family = 'binomial')
summary(logitfit)
ind_HWPI = which(data_recombine_clean$race=="Hawaiian/Pacific Islander")
ind_AI = which(data_recombine_clean$race=="American Indian")
new_data = data_recombine_clean[c(-ind_HWPI,-ind_AI),]
new_data$race = droplevels(new_data$race)
# First regression!
logitfit = glm(decision~gender+race+MCAT+GPA+GPA_sci+casper,data = data_recombine_clean,family = 'binomial')
summary(logitfit)
logitfit = glm(decision~gender+race+MCAT+GPA+GPA_sci+casper,data = new_data,family = 'binomial')
summary(logitfit)
logitfit = glm(decision~gender+race+MCAT+GPA+GPA_sci+casper+year,data = new_data,family = 'binomial')
summary(logitfit)
logitfit = glm(decision~gender+race+MCAT+GPA+GPA_sci+casper+year+year*race,data = new_data,family = 'binomial')
summary(logitfit)
# change base categories and making decision binary variable
data_recombine_clean <- within(data_recombine_clean, gender <- relevel(gender, ref = "Male"))
data_recombine_clean <- within(data_recombine_clean, race <- relevel(race, ref = "Asian"))
data_recombine_clean$decision = (data_recombine_clean$decision=="Admit")
# for these tables, let's remove Hawaiian/PI and American Indian because the groups are so small
ind_HWPI = which(data_recombine_clean$race=="Hawaiian/Pacific Islander")
ind_AI = which(data_recombine_clean$race=="American Indian")
new_data = data_recombine_clean[c(-ind_HWPI,-ind_AI),]
new_data$race = droplevels(new_data$race)
# First regression!
logitfit = glm(decision~gender+race+MCAT+GPA+GPA_sci+casper+year+year*race,data = new_data,family = 'binomial')
summary(logitfit)
# Texas Tech summary
library(vioplot)
library(ggplot2)
library(gapminder)
library(glmnet)
library(xtable)
library(Hmisc)
source("functions.R")
###############################
#  Code Unique to the School  #
###############################
data21 = read.csv("../TTUHSC_2021.csv"); data21$year = 2021
data22 = read.csv("../TTUHSC_2022.csv"); data22$year = 2022
data_all = rbind(data21,data22)
# remove international
i_international = which(data_all$Ethnicity=="International")
data_all = data_all[-i_international,]
# subset to students offered admission
admit_logic =  (data_all$Status_Description=="Matriculated" | data_all$Status_Description=="Withdrawn After Acceptance" | data_all$Status_Description=="Offer Declined" | data_all$Status_Description=="Deferred" | data_all$Status_Description=="Admitted")
# what are the admit ids
ids = which(admit_logic)
# subset data to admits, call it "data"
data = subset(data_all,subset = admit_logic)
# also subset to rejects
data_reject = data_all[-ids,]
# add reject/admit variable
data_reject$decision = "Reject"
data$decision = "Admit"
# data recombine
data_recombine = rbind(data,data_reject)
schoolname = "Texas Tech"
###########################
# data recombine analysis
###########################
# focus on outcomes: (1) MCAT (2) GPA & (3) Science GPA
MCAT = as.numeric(data_recombine$MCAT)
GPA = as.numeric(data_recombine$GPA_Overall)
GPA_sci = as.numeric(data_recombine$GPA_Science)
casper = as.numeric(data_recombine$CASPer)
year = as.factor(data_recombine$year)
status = data_recombine$Status_Description
# extract gender and race variables
gender = data_recombine$Gender
race = data_recombine$Ethnicity
race[race=="Black or African American "] <- "African American"
race[race=="American Indian or Alaska Native Other Hispanic, Latino, or of Spanish origin; Hispanic, Latino, or of Spanish origin; Mexican/Chicano"] <- "American Indian"
race[race=="Black or African American; Other "] <- "African American"
race[race=="Other "] <- "Unreported"
race[race==" "] <- "Unreported"
race[race=="White "] <- "White/Caucasian"
race[race=="White/Caucasian"] <- "White"
race[race=="American Indian or Alaska Native; White Hispanic, Latino, or of Spanish origin; Mexican/Chicano"] <- "American Indian"
race[race==" Hispanic, Latino, or of Spanish origin; Mexican/Chicano"] <- "Hispanic"
race[race==" Puerto Rican; Hispanic, Latino, or of Spanish origin"] <- "Hispanic"
race[race==" Brazillian; Hispanic, Latino, or of Spanish origin"] <- "Hispanic"
race[race==" Dominican; Hispanic, Latino, or of Spanish origin"] <- "Hispanic"
race[race==" Brazil; Hispanic, Latino, or of Spanish origin"] <- "Hispanic"
race[race=="Asian "] <- "Asian"
race[race=="Multiple"] <- "Other"
race[race=="Unreported"] <- "Other"
race = as.factor(race)
gender = as.factor(gender)
decision = as.factor(data_recombine$decision)
# performing similar split to SFFA expert report
race_AA = (race=="African American")
race_AA[which(race_AA==TRUE)] = "African American"
race_AA[which(race_AA=="FALSE")] = "Non-African American"
race_White = (race=="White")
race_White[which(race_White==TRUE)] = "White"
race_White[which(race_White=="FALSE")] = "Non-White"
race_Asian = (race=="Asian")
race_Asian[which(race_Asian==TRUE)] = "Asian"
race_Asian[which(race_Asian=="FALSE")] = "Non-Asian"
# clean data frame with all we need to plot
data_recombine_clean = data.frame(gender,race,MCAT,GPA,GPA_sci,decision,casper,year,race_AA,race_White,race_Asian,status)
sum(data_recombine_clean$decision=="Admit") #check
# change base categories and making decision binary variable
data_recombine_clean <- within(data_recombine_clean, gender <- relevel(gender, ref = "Male"))
data_recombine_clean <- within(data_recombine_clean, race <- relevel(race, ref = "Asian"))
data_recombine_clean$decision = (data_recombine_clean$decision=="Admit")
# for these tables, let's remove Hawaiian/PI and American Indian because the groups are so small
ind_HWPI = which(data_recombine_clean$race=="Hawaiian/Pacific Islander")
ind_AI = which(data_recombine_clean$race=="American Indian")
new_data = data_recombine_clean[c(-ind_HWPI,-ind_AI),]
new_data$race = droplevels(new_data$race)
# First regression!
logitfit = glm(decision~gender+race+MCAT+GPA+GPA_sci+casper+year+year*race,data = new_data,family = 'binomial')
summary(logitfit)
logitfit = glm(decision~1,data = new_data,family = 'binomial')
summary(logitfit)
logit_to_prob <- function(logit) {
1 / (1 + exp(-logit))
}
source("functions.R")
coef(logitfit)
logit_to_prob(coef(logitfit))
mean(new_data$decision)
logitfit = glm(decision~gender+race+MCAT+GPA+GPA_sci+casper+year+year*race,data = new_data,family = 'binomial')
summary(logitfit)
# Texas Tech summary
library(vioplot)
library(ggplot2)
library(gapminder)
library(glmnet)
library(xtable)
library(Hmisc)
source("functions.R")
###############################
#  Code Unique to the School  #
###############################
data21 = read.csv("../TTUHSC_2021.csv"); data21$year = 2021
data22 = read.csv("../TTUHSC_2022.csv"); data22$year = 2022
data_all = rbind(data21,data22)
# remove international
i_international = which(data_all$Ethnicity=="International")
data_all = data_all[-i_international,]
# subset to students offered admission
admit_logic =  (data_all$Status_Description=="Matriculated" | data_all$Status_Description=="Withdrawn After Acceptance" | data_all$Status_Description=="Offer Declined" | data_all$Status_Description=="Deferred" | data_all$Status_Description=="Admitted")
# what are the admit ids
ids = which(admit_logic)
# subset data to admits, call it "data"
data = subset(data_all,subset = admit_logic)
# also subset to rejects
data_reject = data_all[-ids,]
# add reject/admit variable
data_reject$decision = "Reject"
data$decision = "Admit"
# data recombine
data_recombine = rbind(data,data_reject)
schoolname = "Texas Tech"
###########################
# data recombine analysis
###########################
# focus on outcomes: (1) MCAT (2) GPA & (3) Science GPA
MCAT = as.numeric(data_recombine$MCAT)
GPA = as.numeric(data_recombine$GPA_Overall)
GPA_sci = as.numeric(data_recombine$GPA_Science)
casper = as.numeric(data_recombine$CASPer)
year = as.factor(data_recombine$year)
status = data_recombine$Status_Description
# extract gender and race variables
gender = data_recombine$Gender
race = data_recombine$Ethnicity
race[race=="Black or African American "] <- "African American"
race[race=="American Indian or Alaska Native Other Hispanic, Latino, or of Spanish origin; Hispanic, Latino, or of Spanish origin; Mexican/Chicano"] <- "American Indian"
race[race=="Black or African American; Other "] <- "African American"
race[race=="Other "] <- "Unreported"
race[race==" "] <- "Unreported"
race[race=="White "] <- "White/Caucasian"
race[race=="White/Caucasian"] <- "White"
race[race=="American Indian or Alaska Native; White Hispanic, Latino, or of Spanish origin; Mexican/Chicano"] <- "American Indian"
race[race==" Hispanic, Latino, or of Spanish origin; Mexican/Chicano"] <- "Hispanic"
race[race==" Puerto Rican; Hispanic, Latino, or of Spanish origin"] <- "Hispanic"
race[race==" Brazillian; Hispanic, Latino, or of Spanish origin"] <- "Hispanic"
race[race==" Dominican; Hispanic, Latino, or of Spanish origin"] <- "Hispanic"
race[race==" Brazil; Hispanic, Latino, or of Spanish origin"] <- "Hispanic"
race[race=="Asian "] <- "Asian"
race[race=="Multiple"] <- "Other"
race[race=="Unreported"] <- "Other"
race = as.factor(race)
gender = as.factor(gender)
decision = as.factor(data_recombine$decision)
# performing similar split to SFFA expert report
race_AA = (race=="African American")
race_AA[which(race_AA==TRUE)] = "African American"
race_AA[which(race_AA=="FALSE")] = "Non-African American"
race_White = (race=="White")
race_White[which(race_White==TRUE)] = "White"
race_White[which(race_White=="FALSE")] = "Non-White"
race_Asian = (race=="Asian")
race_Asian[which(race_Asian==TRUE)] = "Asian"
race_Asian[which(race_Asian=="FALSE")] = "Non-Asian"
# clean data frame with all we need to plot
data_recombine_clean = data.frame(gender,race,MCAT,GPA,GPA_sci,decision,casper,year,race_AA,race_White,race_Asian,status)
sum(data_recombine_clean$decision=="Admit") #check
# change base categories and making decision binary variable
data_recombine_clean <- within(data_recombine_clean, gender <- relevel(gender, ref = "Male"))
data_recombine_clean <- within(data_recombine_clean, race <- relevel(race, ref = "White"))
data_recombine_clean$decision = (data_recombine_clean$decision=="Admit")
# for these tables, let's remove Hawaiian/PI and American Indian because the groups are so small
ind_HWPI = which(data_recombine_clean$race=="Hawaiian/Pacific Islander")
ind_AI = which(data_recombine_clean$race=="American Indian")
new_data = data_recombine_clean[c(-ind_HWPI,-ind_AI),]
new_data$race = droplevels(new_data$race)
# create equally weighed "academic index"
new_data$AI = (1/3)*new_data$MCAT + (1/3)*new_data$GPA + (1/3)*new_data$GPA_sci
logitfit = glm(decision~gender+race+MCAT+GPA+GPA_sci+casper+year+year*race,data = new_data,family = 'binomial')
summary(logitfit)
mean(new_data$decision[new_data$race=="Asian"])
predict(logitfit)
logit_to_prob(coef(logitfit)) # check that this equals observed
# First regression!
logitfit = glm(decision~1,data = new_data,family = 'binomial')
summary(logitfit)
logit_to_prob(coef(logitfit)) # check that this equals observed
logitfit = glm(decision~race,data = new_data,family = 'binomial')
summary(race)
logitfit = glm(decision~race,data = new_data,family = 'binomial')
summary(logitfit)
logitfit = glm(decision~race+MCAT,data = new_data,family = 'binomial')
summary(logitfit)
logitfit = glm(decision~race,data = new_data,family = 'binomial')
logitfit = glm(decision~race+MCAT+GPA_sci+GPA,data = new_data,family = 'binomial')
summary(logitfit)
logitfit = glm(decision~race+MCAT+GPA_sci+GPA+casper,data = new_data,family = 'binomial')
summary(logitfit)
logitfit = glm(decision~race+MCAT+GPA_sci+GPA+casper+year*race,data = new_data,family = 'binomial')
summary(logitfit)
# First regression!
m1 = glm(decision~MCAT,data = new_data,family = 'binomial')
m2 = glm(decision~GPA,data = new_data,family = 'binomial')
m3 = glm(decision~GPA_sci,data = new_data,family = 'binomial')
m4 = glm(decision~race,data = new_data,family = 'binomial')
m5 = glm(decision~race+MCAT+GPA_sci+GPA+casper,data = new_data,family = 'binomial')
texreg(list(m1,m2,m3,m4,m5),logitfit,float.pos = "H",siunitx=TRUE,single.row = T,custom.model.names = c("Model 1","Model 2","Model 3","Model 4","Model 5"),caption = "logistic regression models of admission probability.")
texreg(list(m1,m2,m3,m4,m5),logitfit,float.pos = "H",siunitx=TRUE,custom.model.names = c("Model 1","Model 2","Model 3","Model 4","Model 5"),caption = "logistic regression models of admission probability.")
sink(file="logittable_all.txt")
texreg(list(m1,m2,m3,m4,m5),logitfit,float.pos = "H",siunitx=TRUE,custom.model.names = c("Model 1","Model 2","Model 3","Model 4","Model 5"),caption = "logistic regression models of admission probability.")
texreg(list(m1,m2,m3,m4,m5),float.pos = "H",siunitx=TRUE,custom.model.names = c("Model 1","Model 2","Model 3","Model 4","Model 5"),caption = "logistic regression models of admission probability.")
sink(file="logittable_all.txt")
texreg(list(m1,m2,m3,m4,m5),float.pos = "H",siunitx=TRUE,custom.model.names = c("Model 1","Model 2","Model 3","Model 4","Model 5"),caption = "logistic regression models of admission probability.")
sink(file=NULL)
# First regression!
m1 = glm(decision~MCAT,data = new_data,family = 'binomial')
m2 = glm(decision~GPA,data = new_data,family = 'binomial')
m3 = glm(decision~GPA_sci,data = new_data,family = 'binomial')
m4 = glm(decision~race,data = new_data,family = 'binomial')
m5 = glm(decision~race+gender+MCAT+GPA_sci+GPA+casper,data = new_data,family = 'binomial')
sink(file="logittable_all.txt")
texreg(list(m1,m2,m3,m4,m5),float.pos = "H",siunitx=TRUE,custom.model.names = c("Model 1","Model 2","Model 3","Model 4","Model 5"),caption = "logistic regression models of admission probability.")
sink(file=NULL)
setwd("~/Library/CloudStorage/Dropbox/SalemCenter/classes/IntroML-MSBAWP/Fall2024/MachineLearning_MSBA-WP/code")
library(tidyverse)
library(ggplot2)
library(usmap)
library(lubridate)
library(randomForest)
library(splines)
library(pdp)
# Note: before loading the data,
# you'll first need to unzip the ercot folder
# (too big for GitHub if not compressed)
# Power grid load every hour for 6 1/2 years
# throughout the 8 ERCOT regions of Texas
# units of grid load are megawatts.
# This represents peak instantaneous demand for power in that hour.
# source: scraped from the ERCOT website
load_data = read.csv("../data/ercot/load_data.csv")
head(load_data)
# Now weather data at hundreds of weather stations
# throughout Texas and the surrounding region
# Note: I've imputed a handful of sporadic missing values
# Source: National Weather Service
temperature_impute = read.csv("../data/ercot/temperature_impute.csv", row.names=1)
station_data = read.csv("../data/ercot/station_data.csv", row.names=1)
# take a peak at the weather station data
head(temperature_impute)
head(station_data)
mysub = which(ymd_hms(load_data$Time) %in% ymd_hms(rownames(temperature_impute)))
load_data = load_data[mysub,]
# De-duplicate the weather data by merging on first match of date in the load data
temp_ind = match(ymd_hms(load_data$Time), ymd_hms(rownames(temperature_impute)))
temperature_impute = temperature_impute[temp_ind,]
# Take the time stamps from the load data
time_stamp = ymd_hms(load_data$Time)
# Verify that the time stamps match row by row across the two data frames
all(time_stamp ==  ymd_hms(rownames(temperature_impute)))
# a lot of these station names are in Mexico or the Gulf
# and we don't have temperature data on them
station_data = subset(station_data, state != 'MX')
# Make a map.
# First, project project the lon, lat coordinates
# to the same coordinate system used by usmap
station_map = station_data %>%
select(lon, lat) %>%
usmap_transform
head(station_map)
# now merge these coordinates station name
station_data = station_data %>% rownames_to_column('station')
station_data = merge(station_data, station_map, by=c('lat', 'lon'))
# a lot of these station names are in Mexico or the Gulf
# and we don't have temperature data on them
station_data = subset(station_data, state != 'MX')
station_map = station_data %>%
select(lon, lat) %>%
usmap_transform
head(station_map)
station_map
View(station_map)
library(tidyverse)
library(ggplot2)
library(usmap)
library(lubridate)
library(randomForest)
library(splines)
library(pdp)
library(sf)
# Note: before loading the data,
# you'll first need to unzip the ercot folder
# (too big for GitHub if not compressed)
# Power grid load every hour for 6 1/2 years
# throughout the 8 ERCOT regions of Texas
# units of grid load are megawatts.
# This represents peak instantaneous demand for power in that hour.
# source: scraped from the ERCOT website
load_data = read.csv("../data/load_data.csv")
# Power grid load every hour for 6 1/2 years
# throughout the 8 ERCOT regions of Texas
# units of grid load are megawatts.
# This represents peak instantaneous demand for power in that hour.
# source: scraped from the ERCOT website
load_data = read.csv("../data/load_ercot.csv")
head(load_data)
# Now weather data at hundreds of weather stations
# throughout Texas and the surrounding region
# Note: I've imputed a handful of sporadic missing values
# Source: National Weather Service
temperature_impute = read.csv("../data/temperature_impute.csv", row.names=1)
station_data = read.csv("../data/station_data.csv", row.names=1)
